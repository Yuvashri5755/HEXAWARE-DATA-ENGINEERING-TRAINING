{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PYSPARK CODING CHALLENGE**\n",
        "\n",
        "DAY 12:23/06/25\n",
        "SUBMITTED BY:YUVASHRI S"
      ],
      "metadata": {
        "id": "O7xsEgXwD9fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and Setup PySpark"
      ],
      "metadata": {
        "id": "UXCjN6BSGTZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WPaVEflXDDm4"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Required Modules and Creating SparkSession"
      ],
      "metadata": {
        "id": "1p2m029VDeAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, dense_rank, sum, avg, mean\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"PySparkExamples\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "rGF4WOyiDQHK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  \n",
        "Given a DataFrame with employee details, calculate the Rank based on Salary for each Department. Use dense_rank() as the ranking function.  "
      ],
      "metadata": {
        "id": "YYRzDEAsDskC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [(\"Alice\", \"HR\", 5000), (\"Bob\", \"Finance\", 7000),\n",
        "         (\"Cathy\", \"HR\", 4500), (\"David\", \"Finance\", 8000)]\n",
        "columns1 = [\"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "df1 = spark.createDataFrame(data1, columns1)\n",
        "\n",
        "windowSpec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
        "ranked_df = df1.withColumn(\"Rank\", dense_rank().over(windowSpec))\n",
        "ranked_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UcDy57xDjIc",
        "outputId": "72d9b0b5-197d-4b58-a658-bfdc658b5bc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+----+\n",
            "| Name|Department|Salary|Rank|\n",
            "+-----+----------+------+----+\n",
            "|David|   Finance|  8000|   1|\n",
            "|  Bob|   Finance|  7000|   2|\n",
            "|Alice|        HR|  5000|   1|\n",
            "|Cathy|        HR|  4500|   2|\n",
            "+-----+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2:  \n",
        "Given the following DataFrame, write a PySpark code to:\n",
        "1. Calculate the total Sales and average Discount for each Category."
      ],
      "metadata": {
        "id": "_Wz2eZGeEZg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data2 = [(\"Electronics\", 1000, 0.1),\n",
        "         (\"Clothing\", 500, 0.2),\n",
        "         (\"Electronics\", 700, 0.15),\n",
        "         (\"Clothing\", 300, 0.25)]\n",
        "columns2 = [\"Category\", \"Sales\", \"Discount\"]\n",
        "\n",
        "df2 = spark.createDataFrame(data2, columns2)\n",
        "\n",
        "# GroupBy and Aggregate\n",
        "agg_df = df2.groupBy(\"Category\") \\\n",
        "            .agg(\n",
        "                sum(\"Sales\").alias(\"TotalSales\"),\n",
        "                avg(\"Discount\").alias(\"AvgDiscount\"))\n",
        "\n",
        "agg_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSpahFv2EfpI",
        "outputId": "71264793-58db-47c7-8342-b81fda2ba89a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-----------+\n",
            "|   Category|TotalSales|AvgDiscount|\n",
            "+-----------+----------+-----------+\n",
            "|Electronics|      1700|      0.125|\n",
            "|   Clothing|       800|      0.225|\n",
            "+-----------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2:\n",
        "Given the following DataFrame, write a PySpark code to:\n",
        "2. Filter the results to show only categories with total sales greater than 1000."
      ],
      "metadata": {
        "id": "e4zqvjA6E8vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter aggregated results\n",
        "filtered_df = agg_df.filter(col(\"TotalSales\") > 1000)\n",
        "filtered_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYZmcmdKFE6O",
        "outputId": "4051cfd4-6253-437c-956f-77b8d3a4fd06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-----------+\n",
            "|   Category|TotalSales|AvgDiscount|\n",
            "+-----------+----------+-----------+\n",
            "|Electronics|      1700|      0.125|\n",
            "+-----------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3:  \n",
        "Write a PySpark code to fill missing values in the Age column with the mean age, and fill missing values in the Name column with \"Unknown\"."
      ],
      "metadata": {
        "id": "jMfs1tVcFI--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = [(\"Alice\", 25), (None, 30), (\"Cathy\", None), (None, None)]\n",
        "columns3 = [\"Name\", \"Age\"]\n",
        "\n",
        "df3 = spark.createDataFrame(data3, columns3)\n",
        "\n",
        "# Compute mean of 'Age'\n",
        "mean_age = df3.select(mean(\"Age\")).first()[0]\n",
        "\n",
        "filled_df3 = df3.fillna({\"Age\": mean_age, \"Name\": \"Unknown\"})\n",
        "filled_df3.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4OJiQVMFNLs",
        "outputId": "dfc89b57-5ff8-46cb-becf-daf52c773726"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|  Alice| 25|\n",
            "|Unknown| 30|\n",
            "|  Cathy| 27|\n",
            "|Unknown| 27|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4:  \n",
        "Given the following DataFrame, filter rows where Age greater than 25 and show the result.  \n",
        "\n"
      ],
      "metadata": {
        "id": "uv64yd4wFSTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data4 = [(\"Alice\", 25), (\"Bob\", 30), (\"Cathy\", 28)]\n",
        "columns4 = [\"Name\", \"Age\"]\n",
        "\n",
        "df4 = spark.createDataFrame(data4, columns4)\n",
        "filtered_df4 = df4.filter(col(\"Age\") > 25)\n",
        "filtered_df4.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E8AFG-kFVc4",
        "outputId": "3a18fcef-c820-4fe6-da8b-566f8a88955e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|  Bob| 30|\n",
            "|Cathy| 28|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5:  \n",
        "Add a new column named AgeAfter5Years that calculates the age of each person after 5 years.  "
      ],
      "metadata": {
        "id": "Lw2Y4mLqFaQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = spark.createDataFrame(data4, columns4)  # reuse previous df\n",
        "df5 = df5.withColumn(\"AgeAfter5Years\", col(\"Age\") + 5)\n",
        "df5.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_WzifuEFeI1",
        "outputId": "480c623b-ec9d-4846-a045-c4b36618a9fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------------+\n",
            "| Name|Age|AgeAfter5Years|\n",
            "+-----+---+--------------+\n",
            "|Alice| 25|            30|\n",
            "|  Bob| 30|            35|\n",
            "|Cathy| 28|            33|\n",
            "+-----+---+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:  \n",
        "Join the following two DataFrames on the ID column and display the result.  "
      ],
      "metadata": {
        "id": "xmDnywgVFjGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Cathy\")]\n",
        "columns1 = [\"ID\", \"Name\"]\n",
        "\n",
        "data2 = [(1, \"HR\"), (2, \"Finance\"), (4, \"IT\")]\n",
        "columns2 = [\"ID\", \"Department\"]\n",
        "\n",
        "df1 = spark.createDataFrame(data1, columns1)\n",
        "df2 = spark.createDataFrame(data2, columns2)\n",
        "\n",
        "joined_df = df1.join(df2, on=\"ID\", how=\"inner\")\n",
        "joined_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4QOL-nbFlza",
        "outputId": "0f2aaa46-2978-40e8-9e9a-0cba4636a1e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| ID| Name|Department|\n",
            "+---+-----+----------+\n",
            "|  1|Alice|        HR|\n",
            "|  2|  Bob|   Finance|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7:  \n",
        "Create a temporary SQL view from the following DataFrame and run a query to select all employees from the \"HR\" department.  "
      ],
      "metadata": {
        "id": "XPAUap5wF_nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data7 = [(\"Alice\", \"HR\", 5000), (\"Bob\", \"Finance\", 7000), (\"Cathy\", \"HR\", 4500)]\n",
        "columns7 = [\"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "df7 = spark.createDataFrame(data7, columns7)\n",
        "\n",
        "# Create temporary view\n",
        "df7.createOrReplaceTempView(\"employees\")\n",
        "\n",
        "# SQL query\n",
        "result = spark.sql(\"SELECT * FROM employees WHERE Department = 'HR'\")\n",
        "result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc_uRQMIGCgB",
        "outputId": "9fef633f-55e1-482d-d640-e4ce417abdba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "|Alice|        HR|  5000|\n",
            "|Cathy|        HR|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}